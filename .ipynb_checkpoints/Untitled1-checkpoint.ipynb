{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a664b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdFMCS\n",
    "from rdkit.Chem import PandasTools\n",
    "\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pubchempy as pcp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd918cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/Users/mahnoorzulfiqar/OneDriveUNI/CondaCheck/'\n",
    "# read the suspect list\n",
    "slistcsv = \"/Users/mahnoorzulfiqar/OneDriveUNI/CondaCheck/SkeletonemaSuspectListV1.csv\"\n",
    "# read input_table.csv generated in the R workflow\n",
    "input_tablecsv = input_dir + \"input_table.csv\"\n",
    "sl = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41569ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score                                              InChI  \\\n",
      "0    1.0  InChI=1S/C19H14ClF5N4O2/c20-14-7-6-13(8-12(14)...   \n",
      "\n",
      "  FragmenterScore_Values  SuspectListScore  MaximumTreeDepth  \\\n",
      "0          1324.0;1572.0               0.0                 2   \n",
      "\n",
      "   MonoisotopicMass CompoundName Identifier MolecularFormula  \\\n",
      "0         460.07257     Flupoxam     C18543   C19H14ClF5N4O2   \n",
      "\n",
      "                                 FormulasOfExplPeaks   InChIKey2  \\\n",
      "0  66.0469703041635:[C5H5+H]-;193.997356261979:[C...  UHFFFAOYSA   \n",
      "\n",
      "        InChIKey1  FragmenterScore  \\\n",
      "0  AOQMRUTZEYVDIL        26.477126   \n",
      "\n",
      "                                       ExplPeaks                     InChIKey  \\\n",
      "0  66.0469703041635_818.3;193.997356261979_804.5  AOQMRUTZEYVDIL-UHFFFAOYSA-N   \n",
      "\n",
      "   NoExplPeaks  NumberPeaksUsed  \n",
      "0            2               48  \n",
      "Empty DataFrame\n",
      "Columns: [Score, InChI, FragmenterScore_Values, SuspectListScore, MaximumTreeDepth, MonoisotopicMass, CompoundName, Identifier, MolecularFormula, FormulasOfExplPeaks, InChIKey2, InChIKey1, FragmenterScore, ExplPeaks, InChIKey, NoExplPeaks, NumberPeaksUsed]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/mawRpy/lib/python3.10/site-packages/pandas/core/indexes/range.py:385\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m PubChem_file \u001b[38;5;241m=\u001b[39m PubChem_file\u001b[38;5;241m.\u001b[39mdrop(PubChem_file[PubChem_file\u001b[38;5;241m.\u001b[39mScore \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.75\u001b[39m]\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# add the relavnt information to the original MS1DATA csv\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m file1\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPC_ID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mPubChem_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIdentifier\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    106\u001b[0m file1\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPC_Name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PubChem_file\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIUPACName\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    107\u001b[0m file1\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPC_Formula\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PubChem_file\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMolecularFormula\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mawRpy/lib/python3.10/site-packages/pandas/core/indexing.py:960\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    958\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m--> 960\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mawRpy/lib/python3.10/site-packages/pandas/core/frame.py:3622\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   3616\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[1;32m   3618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   3619\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[1;32m   3620\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[0;32m-> 3622\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[row]\n\u001b[1;32m   3625\u001b[0m \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mawRpy/lib/python3.10/site-packages/pandas/core/indexes/range.py:387\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 387\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "heavy_atoms = ['C', 'N', 'P', 'O', 'S']\n",
    "\n",
    "input_table = pd.read_csv(input_tablecsv)\n",
    "\n",
    "for m, row in input_table.iterrows():\n",
    "\n",
    "    # Result directory\n",
    "    result = input_dir + (input_table['ResultFileNames'][m] + \n",
    "                             '/insilico/MetFrag').replace(\"./\", \"\")\n",
    "\n",
    "    # list of all the csv files in the result directory result_dir/inislico/MetFrag/\n",
    "    files_met = (glob.glob(result+'/*.csv'))\n",
    "\n",
    "    # read the csv file that contains all the features from the input .mzml file\n",
    "    file1  = pd.read_csv(input_dir + (input_table['ResultFileNames'][m] + '/insilico/MS1DATA.csv').replace(\"./\", \"\"))\n",
    "\n",
    "    # for each feature in the MS1DATA.csv file\n",
    "    for i, row in file1.iterrows():\n",
    "\n",
    "        # take id as a pattern to differentiate between different ids\n",
    "        pattern = file1.loc[i, \"id_X\"]\n",
    "\n",
    "        #check which of the csv result files have the same pattern in their names\n",
    "        results = [i for i in files_met if pattern in i]\n",
    "\n",
    "        # find which of the files with that id have KEGG in their names,\n",
    "        KEGG = [i for i in results if \"KEGG\" in i]\n",
    "\n",
    "        # if kegg present in the name\n",
    "        if KEGG:\n",
    "\n",
    "            # read the KEGG csv file for that feature\n",
    "            KEGG_file = pd.read_csv((KEGG)[0])\n",
    "\n",
    "            # if the KEGG file isn't empty\n",
    "            if len(KEGG_file) >= 1:\n",
    "\n",
    "                # extract only the columns with >0.75 score\n",
    "                KEGG_file = KEGG_file.drop(KEGG_file[KEGG_file.Score < 0.75].index)\n",
    "                print(KEGG_file)\n",
    "                \n",
    "                if len(KEGG_file) >= 1:\n",
    "\n",
    "                    # add the relavnt information to the original MS1DATA csv\n",
    "                    file1.loc[i, 'KG_ID'] = KEGG_file.loc[0, 'Identifier']\n",
    "                    file1.loc[i, 'KG_Name'] = KEGG_file.loc[0, 'CompoundName']\n",
    "                    file1.loc[i, 'KG_Formula'] = KEGG_file.loc[0, 'MolecularFormula']\n",
    "                    file1.loc[i, 'KG_expPeaks'] = KEGG_file.loc[0, 'NoExplPeaks']\n",
    "                    file1.loc[i, 'KG_SMILES'] = Chem.MolToSmiles(Chem.MolFromInchi(KEGG_file[\"InChI\"][0]))\n",
    "                    file1.loc[i, 'KG_file'] = KEGG\n",
    "\n",
    "                    #create empty list of KEGG top smiles\n",
    "                    Kegg_smiles = []\n",
    "\n",
    "                    # extract only the InChI of the top 5\n",
    "                    for j in KEGG_file[\"InChI\"][0:5].tolist():\n",
    "                        # convert the InChI to SMILES\n",
    "                        mol = Chem.MolToSmiles(Chem.MolFromInchi(j))\n",
    "                        if sl:\n",
    "                            # read the suspect list\n",
    "                            slist = pd.read_csv(slistcsv)\n",
    "\n",
    "                            # Add columns \n",
    "                            file1['KG_Top_can_SL'] = np.nan # top candidate among the top 5 candidates, according to similarity with a compound in suspect list\n",
    "                            file1['KG_tanimotoSLvsCAN'] = np.nan # tanimoto score\n",
    "                            file1['KG_SL_comp'] = np.nan # Smiles of the suspect listr compund with  high similairity with the one of the top 5 candidates\n",
    "\n",
    "                            # for each smiles in suspect list\n",
    "                            for k, row in slist.iterrows():\n",
    "                                # Calculate the tanimoto score\n",
    "                                SSms = [Chem.MolFromSmiles(mol), Chem.MolFromSmiles(slist['SMILES'][k])]\n",
    "                                SSfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in SSms]\n",
    "                                SStn = DataStructs.FingerprintSimilarity(SSfps[0],SSfps[1])\n",
    "                                if SStn >= 0.8:\n",
    "                                    file1.loc[i, 'KG_Top_can_SL'] = j\n",
    "                                    file1.loc[i, 'KG_tanimotoSLvsCAN'] = SStn\n",
    "                                    file1.loc[i, 'KG_SL_comp'] = slist['SMILES'][k]\n",
    "                        mol2 = Chem.MolFromSmiles(mol)\n",
    "                        Kegg_smiles.append(mol2)\n",
    "                    # if there are more than 1 top smiles\n",
    "                    if len(Kegg_smiles) > 1:\n",
    "                        #calculate the MCSS\n",
    "                        res = rdFMCS.FindMCS(Kegg_smiles)\n",
    "                        sm_res = Chem.MolToSmiles(Chem.MolFromSmarts(res.smartsString))\n",
    "                        # if there are atleast 3 heavy atoms in the MCSS, then add it to the result file\n",
    "                        elem = [ele for ele in heavy_atoms if(ele in sm_res)]\n",
    "                        if elem and len(sm_res)>=3:\n",
    "                            file1.loc[i, 'KG_MCSSstring'] = res.smartsString\n",
    "                            file1.loc[i, 'KG_MCSS_SMILES'] = Chem.MolToSmiles(Chem.MolFromSmarts(res.smartsString))\n",
    "\n",
    "        #start here for PubChem; find which of the files with that id have PubChem in their names,\n",
    "        PubChem = [i for i in results if \"PubChem\" in i]\n",
    "\n",
    "        if PubChem:\n",
    "\n",
    "            PubChem_file = pd.read_csv(PubChem[0])\n",
    "\n",
    "            # if more candidates\n",
    "            if len(PubChem_file) >= 1:\n",
    "\n",
    "                # take the ones with more than 0.75 score\n",
    "                PubChem_file = PubChem_file.drop(PubChem_file[PubChem_file.Score < 0.75].index)\n",
    "                \n",
    "                if len(PubChem_file) >= 1:\n",
    "\n",
    "                    # add the relavnt information to the original MS1DATA csv\n",
    "                    file1.loc[i, 'PC_ID'] = PubChem_file.loc[0, 'Identifier']\n",
    "                    file1.loc[i, 'PC_Name'] = PubChem_file.loc[0, 'IUPACName']\n",
    "                    file1.loc[i, 'PC_Formula'] = PubChem_file.loc[0, 'MolecularFormula']\n",
    "                    file1.loc[i, 'PC_expPeaks'] = PubChem_file.loc[0, 'NoExplPeaks']\n",
    "                    file1.loc[i, 'PC_SMILES'] = PubChem_file[\"SMILES\"][0]\n",
    "                    file1.loc[i, 'PC_file'] = PubChem\n",
    "\n",
    "                    # empty object\n",
    "                    Pubchem_smiles = []\n",
    "\n",
    "                    # extract only the SMILES of the top 5\n",
    "                    for j in PubChem_file[\"SMILES\"][0:5].tolist():\n",
    "\n",
    "                        # if sl = True\n",
    "                        if sl:\n",
    "\n",
    "                            # read the suspect list\n",
    "                            slist = pd.read_csv(slistcsv)\n",
    "    \n",
    "                            # Add columns \n",
    "                            file1['PC_Top_can_SL'] = np.nan # top candidate among the top 5 candidates, according to similarity with a compound in suspect list\n",
    "                            file1['PC_tanimotoSLvsCAN'] = np.nan # tanimoto score\n",
    "                            file1['PC_SL_comp'] = np.nan # Smiles of the suspect listr compund with  high similairity with the one of the top 5 candidates\n",
    "                            # calculate tanimoto\n",
    "                            for n, row in slist.iterrows():\n",
    "    \n",
    "                                SSms = [Chem.MolFromSmiles(j), Chem.MolFromSmiles(slist['SMILES'][n])]\n",
    "                                SSfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in SSms]\n",
    "                                SStn2 = DataStructs.FingerprintSimilarity(SSfps[0],SSfps[1])\n",
    "\n",
    "                                if SStn2 >= 0.8:\n",
    "                                    file1.loc[i, 'PC_Top_can_SL'] = j\n",
    "                                    file1.loc[i, 'PC_tanimotoSLvsCAN'] = SStn2\n",
    "                                    file1.loc[i, 'PC_SL_comp'] = slist['SMILES'][n]\n",
    "\n",
    "                        # Concert smiles to mol\n",
    "                        sm2 = Chem.MolFromSmiles(j)\n",
    "                        # store mol in Pubchem_smiles\n",
    "                        Pubchem_smiles.append(sm2)\n",
    "\n",
    "                    if len(Pubchem_smiles) > 1:\n",
    "                        # calculate MCSS\n",
    "                        res2 = rdFMCS.FindMCS(Pubchem_smiles)\n",
    "                        sm_res = Chem.MolToSmiles(Chem.MolFromSmarts(res2.smartsString))\n",
    "                        # If atleast 3 heavy atoms present\n",
    "                        elem = [ele for ele in heavy_atoms if(ele in sm_res)]\n",
    "                        if elem and len(sm_res)>=3:\n",
    "                            file1.loc[i, 'PC_MCSSstring']= res2.smartsString\n",
    "                            file1.loc[i, 'PC_MCSS_SMILES'] = Chem.MolToSmiles(Chem.MolFromSmarts(res2.smartsString))\n",
    "    file1.to_csv(input_dir + (input_table['ResultFileNames'][m] + '/insilico/MetFragResults.csv').replace(\"./\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbb491e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Score, MonoisotopicMass, SMILES, InChIKey, NoExplPeaks, NumberPeaksUsed, InChI, MaximumTreeDepth, Identifier, ExplPeaks, InChIKey2, InChIKey1, IUPACName, FragmenterScore, MolecularFormula, FragmenterScore_Values, FormulasOfExplPeaks, SuspectListScore, XlogP3]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(PubChem_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0998d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(KEGG_file) <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed81b118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mawRpy)",
   "language": "python",
   "name": "mawrpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
