{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b97891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# import pubchempy as pcp\n",
    "# import numpy as np\n",
    "# def isNaN(string):\n",
    "#     return string != string\n",
    "# import os\n",
    "# import glob\n",
    "# import re\n",
    "# from pybatchclassyfire import *\n",
    "# import csv \n",
    "# import time\n",
    "# import json\n",
    "# from pandas import json_normalize\n",
    "# import wget\n",
    "# import string\n",
    "# import urllib.parse\n",
    "# import openpyxl\n",
    "# import statistics\n",
    "# import sys\n",
    "# from itertools import chain\n",
    "# from rdkit import Chem\n",
    "# from rdkit import DataStructs\n",
    "# from rdkit.Chem import AllChem\n",
    "# from rdkit.Chem import rdFMCS\n",
    "# from rdkit.Chem import PandasTools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396db87f",
   "metadata": {},
   "source": [
    "## MetFrag Suspect List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16991cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make sure your Smiles entries in the suspect list csv are in a column named \"SMILES\"\n",
    "# def slist_metfrag(input_dir, slist_csv, name):\n",
    "#     \"\"\"slist_metfrag is used to create a txt file that contains a list of \n",
    "#     InChIKeys. This list is later used by MetFrag to use these compounds \n",
    "#     as a Suspect List.\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored. For this \n",
    "#     function this directory must contain a csv file that has a column \n",
    "#     named \"SMILES\".\n",
    "    \n",
    "#     slist_csv (str): This is the csv file that contains a column of \n",
    "#     \"SMILES\". Additionally this file can contain other information \n",
    "#     about the compounds, but for this function, column of \"SMILES\", \n",
    "#     named as \"SMILES\" is necessary.\n",
    "\n",
    "#     Returns:\n",
    "#     list: list of InChIKeys\n",
    "#     txt: a txt file of list of InChIKeys, is stored in input_dir\n",
    "    \n",
    "#     Usage:\n",
    "#     slist_metfrag(input_dir = \"/user/project/\", slist_csv = \n",
    "#     \"suspectlist.csv\")\n",
    "    \n",
    "#     \"\"\"\n",
    "#     sl = pd.read_csv(slist_csv)\n",
    "#     sl_mtfrag= []\n",
    "#     for i, rows in sl.iterrows():\n",
    "#         if i is not None:\n",
    "#             mols = Chem.MolFromSmiles(sl['SMILES'][i])\n",
    "#             try:\n",
    "#                 sl.loc[i, 'InChIKey'] = Chem.inchi.MolToInchiKey(mols)\n",
    "#                 sl_mtfrag.append(sl['InChIKey'][i])\n",
    "#             except Exception as e:\n",
    "#                 print(e)\n",
    "    \n",
    "#     with open((input_dir + \"/SL_\"+ name + '.txt'), 'w') as filehandle:\n",
    "#         for listitem in sl_mtfrag:\n",
    "#             filehandle.write('%s\\n' % listitem)\n",
    "#     return(sl_mtfrag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e680ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def spec_postproc(input_dir, Source = \"all\"):\n",
    "    \n",
    "#     \"\"\"spec_postproc function processes the resulst from dereplication \n",
    "#     using different spectral DBs. \n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "    \n",
    "#     Source (str): either \"mbank\" or \"hmdb\" or \"gnps\", or \"all\"\n",
    "\n",
    "#     Returns:\n",
    "    \n",
    "#     dataframe: of the paths of the processed DB results\n",
    "    \n",
    "    \n",
    "#     Usage:\n",
    "#     spec_postproc(input_dir = \"/user/project/\", Source = \"all\")\n",
    "\n",
    "#     \"\"\"\n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "\n",
    "#     # empty lists of csv files paths for each database\n",
    "#     GNPScsvfiles = []\n",
    "#     HMDBcsvfiles = []\n",
    "#     MassBankcsvfiles = []\n",
    "    \n",
    "#     #list all files and directories\n",
    "#     for entry in os.listdir(input_dir):\n",
    "#         if os.path.isdir(os.path.join(input_dir, entry)):\n",
    "            \n",
    "#             # enter the directory with /spectral_dereplication/ results\n",
    "#             sub_dir = input_dir + entry + '/spectral_dereplication'\n",
    "#             if os.path.exists(sub_dir):\n",
    "#                 files = (glob.glob(sub_dir+'/*.csv'))\n",
    "\n",
    "#                 for f in files:\n",
    "#                     if 'gnps.' in f: \n",
    "#                         GNPScsvfiles.append(f)\n",
    "#                     if 'hmdb.' in f: \n",
    "#                         HMDBcsvfiles.append(f)\n",
    "#                     if 'mbank.' in f: \n",
    "#                         MassBankcsvfiles.append(f)\n",
    "                            \n",
    "    \n",
    "#     if Source == \"hmdb\" or Source == \"all\":\n",
    "\n",
    "#         if not os.path.exists(input_dir+\"structures.sdf\"):\n",
    "#             #download SDF structures\n",
    "#             os.system(\"wget -P \" + input_dir + \" https://hmdb.ca/system/downloads/current/structures.zip\")\n",
    "#             os.system(\"unzip \"+ input_dir + \"structures.zip\" + \" -d \" + input_dir)\n",
    "            \n",
    "#         # Load the sdf\n",
    "#         dframe = PandasTools.LoadSDF((input_dir+\"structures.sdf\"),\n",
    "#                                      idName='HMDB_ID',smilesName='SMILES',\n",
    "#                                      molColName='Molecule', includeFingerprints=False)\n",
    "        \n",
    "#         #### read sdf file from HMDB to collect names and smiles ####\n",
    "    \n",
    "#         #HMDB CSV Result file pre_processing\n",
    "        \n",
    "#         #open another csv path holding empty list, which will be filled \n",
    "#         #with post processed csv results\n",
    "#         HMDBcsvfiles2 = []\n",
    "        \n",
    "#         for k in HMDBcsvfiles:\n",
    "            \n",
    "#             # read the csv files\n",
    "#             hmdb_df = pd.read_csv(k)\n",
    "            \n",
    "#             # merge on basis of id, frame and hmdb result files\n",
    "#             SmilesHM = pd.merge(hmdb_df, dframe, left_on=hmdb_df.HMDBcompoundID, right_on=dframe.DATABASE_ID)\n",
    "            \n",
    "            \n",
    "#             for i, row in hmdb_df.iterrows():\n",
    "                \n",
    "#                 for j, row in SmilesHM.iterrows():\n",
    "                    \n",
    "#                     # where index for both match, add the name and SMILES\n",
    "#                     if hmdb_df['id_X'][i]== SmilesHM['id_X'][j]:\n",
    "#                         hmdb_df.loc[i, 'HMDBSMILES'] = SmilesHM['SMILES'][j]#add SMILES\n",
    "#                         hmdb_df.loc[i, 'HMDBcompound_name'] = SmilesHM[\"GENERIC_NAME\"][j]#add name\n",
    "#                         hmdb_df.loc[i, 'HMDBformula'] = SmilesHM[\"FORMULA\"][j]#add formula\n",
    "                \n",
    "#             csvname = (os.path.splitext(k)[0])+\"proc\"+\".csv\" # name for writing it in a new file\n",
    "#             hmdb_df.to_csv(csvname) #write\n",
    "#             HMDBcsvfiles2.append(csvname)# add to a list\n",
    "#             dict1 = {'HMDBr': HMDBcsvfiles2} \n",
    "#             df = pd.DataFrame(dict1)\n",
    "        \n",
    "#     #MassBank CSV Result file pre_processing\n",
    "    \n",
    "#     if Source == \"mbank\" or Source == \"all\":\n",
    "        \n",
    "#         #open another csv path holding empty list, which will be filled \n",
    "#         #with post processed csv results\n",
    "#         MassBankcsvfiles2 = []\n",
    "        \n",
    "#         for l in MassBankcsvfiles:\n",
    "            \n",
    "#             # read mbank csv file\n",
    "#             mbank_df = pd.read_csv(l)\n",
    "            \n",
    "#             for i, row in mbank_df.iterrows():\n",
    "                \n",
    "#                 inchiK = str(mbank_df[\"MBinchiKEY\"][i])\n",
    "                \n",
    "#                 #extract inchikeys\n",
    "#                 y = pcp.get_compounds(inchiK, 'inchikey')#compound based on inchikey\n",
    "                \n",
    "#                 for compound in y:\n",
    "                    \n",
    "#                     #add smiles\n",
    "#                     smles = compound.isomeric_smiles   \n",
    "#                     mbank_df.loc[i, 'MBSMILES'] = smles\n",
    "                    \n",
    "#             csvname = (os.path.splitext(l)[0])+\"proc\"+\".csv\"\n",
    "#             mbank_df.to_csv(csvname)\n",
    "#             MassBankcsvfiles2.append(csvname)\n",
    "            \n",
    "#             dict1 = {'MBr': MassBankcsvfiles2} \n",
    "#             df = pd.DataFrame(dict1)\n",
    "    \n",
    "#     # GNPS CSV Result file pre_processing\n",
    "#     if Source == \"gnps\" or Source == \"all\":\n",
    "#         #open another csv path holding empty list, which will be filled \n",
    "#         #with post processed csv results\n",
    "#         GNPScsvfiles2 = []\n",
    "#         #currently only these subsets are removed from the names from GNPS\n",
    "#         matches = [\"M+\",\"[M\", \"M-\", \"2M\", \"M*\" \"20.0\", \"50.0\", \"30.0\", \"40.0\", \"60.0\", \"70.0\", \"eV\", \"Massbank\"\n",
    "#                , \"Spectral\", \"Match\", \"to\", \"from\", \"NIST14\", \"MoNA\", '[IIN-based:',  '[IIN-based', 'on:', 'CCMSLIB00003136269]']\n",
    "\n",
    "#         for l in GNPScsvfiles:\n",
    "#             gnps_df = pd.read_csv(l)\n",
    "\n",
    "#             for i, row in gnps_df.iterrows():\n",
    "#                 # if compound name is present\n",
    "#                 if not isNaN(gnps_df['GNPScompound_name'][i]):\n",
    "#                     # split if there is a gap in the names\n",
    "#                     string_chng = (gnps_df['GNPScompound_name'][i].split(\" \"))\n",
    "\n",
    "#                     # create an empty list\n",
    "#                     newstr = []\n",
    "\n",
    "#                     # for each part of the string in the names\n",
    "#                     chng = []\n",
    "\n",
    "#                     for j in range(len(string_chng)):\n",
    "\n",
    "#                         # check if the substrings are present in the matches and no - is present\n",
    "#                         if not any(x in string_chng[j] for x in matches): #and not '-' == string_chng[j]:\n",
    "\n",
    "#                             # IF | and ! not in the substring\n",
    "#                             if '|' not in string_chng[j] or '!' not in string_chng[j]:\n",
    "#                                 newstr.append(string_chng[j])\n",
    "\n",
    "#                             # if | present in the substring   \n",
    "#                             elif '|' in string_chng[j]:\n",
    "\n",
    "#                                 #split the string\n",
    "#                                 jlen = string_chng[j].split(\"|\")\n",
    "#                                 #how many substrings are left now\n",
    "#                                 lst = len(jlen)-1\n",
    "#                                 #append this to chng\n",
    "#                                 chng.append(jlen[lst])\n",
    "#                                 break\n",
    "\n",
    "#                     # now append chng to newstr            \n",
    "#                     chng.append(' '.join(newstr))\n",
    "#                     #save this as the correct name\n",
    "#                     gnps_df.loc[i, \"corr_names\"] = chng[0]\n",
    "#                     if not isNaN(gnps_df['GNPSSMILES'][i]):\n",
    "#                         if chng == '':\n",
    "#                             break\n",
    "#                         elif gnps_df['GNPSSMILES'][i].isalpha():\n",
    "#                             s = pcp.get_compounds(chng[0], 'name')\n",
    "#                             if s:\n",
    "#                                 for comp in s:\n",
    "#                                     gnps_df[\"GNPSSMILES\"][i] = comp.isomeric_smiles\n",
    "#                             else:\n",
    "#                                 gnps_df[\"GNPSSMILES\"][i] = ''\n",
    "#                 else:\n",
    "#                     gnps_df[\"GNPSSMILES\"][i] = ''\n",
    "\n",
    "#             for i, row in gnps_df.iterrows():\n",
    "#                 if isNaN(gnps_df['GNPSSMILES'][i]):\n",
    "#                     if \"[\" in gnps_df['GNPScompound_name'][i].split(\" \")[-1]:\n",
    "#                         string_chng = (gnps_df['GNPScompound_name'][i].split(\"[\"))\n",
    "#                         #print(gnps_df['GNPScompound_name'][i])\n",
    "#                         keep_names = []\n",
    "#                         for j in range(len(string_chng)-1):\n",
    "#                             gnps_df.loc[i, \"corr_names\"] == string_chng[j]\n",
    "#                             s = pcp.get_compounds(string_chng[j], 'name')\n",
    "\n",
    "#                             if s:\n",
    "#                                 for comp in s:\n",
    "#                                     gnps_df[\"GNPSSMILES\"][i] = comp.isomeric_smiles\n",
    "#                             else:\n",
    "#                                 gnps_df[\"GNPSSMILES\"][i] = ''\n",
    "#                 if not isNaN(gnps_df['GNPSSMILES'][i]):\n",
    "#                     try:\n",
    "#                         sx = pcp.get_compounds(gnps_df['GNPSSMILES'][i], 'smiles')\n",
    "#                         if sx:\n",
    "#                             sx = str(sx)\n",
    "#                             comp = pcp.Compound.from_cid([int(x) for x in re.findall(r'\\b\\d+\\b', sx)])\n",
    "#                             gnps_df.loc[i, 'GNPSformula'] = comp.molecular_formula\n",
    "#                     except:\n",
    "#                         gnps_df.loc[i, 'GNPSformula'] = ''\n",
    "\n",
    "#             csvname = (os.path.splitext(l)[0])+\"proc\"+\".csv\"\n",
    "#             gnps_df.to_csv(csvname)\n",
    "#             GNPScsvfiles2.append(csvname)\n",
    "#             dict1 = {'GNPSr': GNPScsvfiles2} \n",
    "#             df = pd.DataFrame(dict1)\n",
    "        \n",
    "\n",
    "#     if Source == \"all\":\n",
    "        \n",
    "#         dict1 = {'GNPSr': GNPScsvfiles2, 'HMDBr': HMDBcsvfiles2, 'MBr': MassBankcsvfiles2} \n",
    "#         df = pd.DataFrame(dict1)\n",
    "\n",
    "#         return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daf5cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sirius_postProc2(input_dir, input_tablecsv):\n",
    "    \n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "#     \"\"\"sirius_postProc2 is the second part of the function \n",
    "#     sirius_postProc defined in R part of the workflow. This function\n",
    "#     re-checks the Suspect list, if present or given as a parameter, \n",
    "#     whether the candidates have a high similarity with compounds in\n",
    "#     Suspect List. It also calculates the Maximum Common Substructure\n",
    "#     (MCSS)\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored. For this \n",
    "#     function this directory must contain a csv file that has a column \n",
    "#     named \"SMILES\".\n",
    "    \n",
    "#     input_tablecsv (str): This is the table in csv format (defined in R), \n",
    "#     which stores a csv table containing columns \"mzml_files\", which \n",
    "#     contains liat of all input files with their relative paths, second\n",
    "#     column is \"ResultFileName\" which is a list of the corresponding\n",
    "#     result relative directories to each mzml files. Lastly, \"file_id\", \n",
    "#     contains a file directory. This table will be used to read the \n",
    "#     SIRIUS json files\n",
    "    \n",
    "\n",
    "#     Returns:\n",
    "#     csv: a result file with additional columns such as those for suspect\n",
    "#     list if one is used. It also adds columns on MCSS., named as \n",
    "#     \"input_dir/ResultFileName/insilico/SiriusResults.csv\"\n",
    "    \n",
    "    \n",
    "#     Usage:\n",
    "#     sirius_postProc2(input_dir = \"/user/project/\", \n",
    "#     input_table = \"/user/project/suspectlist.csv\")\n",
    "\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Describe the heavy atoms to be considered for MCSS\n",
    "#     heavy_atoms = ['C', 'N', 'P', 'O', 'S']\n",
    "    \n",
    "#     input_table = pd.read_csv(input_tablecsv)\n",
    "    \n",
    "#     for m, row in input_table.iterrows():\n",
    "        \n",
    "#         # Read the file result_dir/insilico/MS1DATAsirius.csv. \n",
    "#         # This file has been produced in R workflow and contains \n",
    "#         # SIRIUS results.\n",
    "\n",
    "#         file1 = pd.read_csv(input_dir + (input_table['ResultFileNames'][m] + '/insilico/MS1DATAsirius.csv').replace(\"./\", \"\"))\n",
    "        \n",
    "#         for i, row in file1.iterrows():\n",
    "            \n",
    "#             # if the entry has SMILES extracted for MCSS calculation\n",
    "#             if not isNaN(file1['SMILESforMCSS'][i]):\n",
    "                \n",
    "#                 # split the SMILES using |\n",
    "#                 top_smiles = file1['SMILESforMCSS'][i].split(\"|\")\n",
    "                \n",
    "#                 # if there are more than 1 smiles in the top smiles, \n",
    "#                 if len(top_smiles) > 1:\n",
    "#                     mol = []\n",
    "#                     for j in top_smiles:\n",
    "#                         n = Chem.MolFromSmiles(j)\n",
    "#                         mol.append(n)\n",
    "#                     # list of mol used to calaculate the MCSS\n",
    "#                     res = rdFMCS.FindMCS(mol)\n",
    "#                     sm_res = Chem.MolToSmiles(Chem.MolFromSmarts(res.smartsString))\n",
    "#                     # Check if the MCSS has one of the heavy atoms and whether they are\n",
    "#                     # more than 3\n",
    "#                     elem = [ele for ele in heavy_atoms if(ele in sm_res)]\n",
    "#                     if elem and len(sm_res)>=3:\n",
    "#                         file1.loc[i, 'MCSSstring'] = res.smartsString\n",
    "#                         file1.loc[i, 'MCSS_SMILES'] = Chem.MolToSmiles(Chem.MolFromSmarts(res.smartsString))\n",
    "                        \n",
    "                        \n",
    "#             if file1[\"FormulaRank\"][i] == 1.0:\n",
    "#                 sep = 'json/'\n",
    "#                 strpd = file1[\"dir\"][i].split(sep, 1)[0] +\"json/canopus_summary.tsv\"\n",
    "#                 if os.path.isfile(strpd):\n",
    "\n",
    "#                     canopus = pd.read_csv(strpd, sep='\\t')\n",
    "#                     if len(canopus) > 0:\n",
    "#                         #file1.loc[i, 'most_specific_class'] = canopus[\"most specific class\"][0]\n",
    "#                         #file1.loc[i, 'level _5'] = canopus[\"level 5\"][0]\n",
    "#                         file1.loc[i, 'subclass'] = canopus[\"subclass\"][0]\n",
    "#                         file1.loc[i, 'class'] = canopus[\"class\"][0]\n",
    "#                         file1.loc[i, 'superclass'] = canopus[\"superclass\"][0]\n",
    "#                         #file1.loc[i, 'all_classifications'] = canopus[\"all classifications\"][0]\n",
    "#                         file1.loc[i, 'Classification_Source'] = 'CANOPUS'\n",
    "                    \n",
    "        \n",
    "#         file1.to_csv(input_dir + (input_table['ResultFileNames'][m] + '/insilico/SiriusResults.csv').replace(\"./\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d340d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def metfrag_postproc(input_dir, input_tablecsv, sl= True):\n",
    "    \n",
    "    \n",
    "#     \"\"\"metfrag_postproc function re-checks the Suspect list, if present \n",
    "#     or given as a parameter, whether the candidates have a high \n",
    "#     similarity with compounds in Suspect List. It also calculates the \n",
    "#     Maximum Common Substructure (MCSS). This function adds top candidates\n",
    "#     from PubChem and KEGG as these two databases are used with MetFrag\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored. For this \n",
    "#     function this directory must contain a csv file that has a column \n",
    "#     named \"SMILES\".\n",
    "    \n",
    "#     input_tablecsv (str): This is the table in csv format (defined in R), \n",
    "#     which stores a csv table containing columns \"mzml_files\", which \n",
    "#     contains liat of all input files with their relative paths, second\n",
    "#     column is \"ResultFileName\" which is a list of the corresponding\n",
    "#     result relative directories to each mzml files. Lastly, \"file_id\", \n",
    "#     contains a file directory. This table will be used to read the \n",
    "#     MetFrag csv files\n",
    "\n",
    "#     Returns:\n",
    "#     csv: a result file with additional columns such as those for suspect\n",
    "#     list if one is used. It also adds columns on MCSS., named as \n",
    "#     \"input_dir/ResultFileName/insilico/MetFragResults.csv\". It \n",
    "#     contains columns for KEGG and PubChem\n",
    "    \n",
    "    \n",
    "#     Usage:\n",
    "#     metfrag_postproc(input_dir = \"/user/project/\", \n",
    "#     input_table = \"/user/project/suspectlist.csv\", sl = True, slistcsv)\n",
    "\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Describe the heavy atoms to be considered for MCSS\n",
    "#     heavy_atoms = ['C', 'N', 'P', 'O', 'S']\n",
    "    \n",
    "#     input_table = pd.read_csv(input_tablecsv)\n",
    "    \n",
    "#     for m, row in input_table.iterrows():\n",
    "        \n",
    "#         # read SIRIUS results:\n",
    "        \n",
    "#         #siriusResults = pd.read_csv(input_dir + (input_table['ResultFileNames'][m] + '/insilico/SiriusResults.csv'))\n",
    "    \n",
    "#         # Result directory\n",
    "#         result = input_dir + (input_table['ResultFileNames'][m] + \n",
    "#                                  '/insilico/MetFrag').replace(\"./\", \"\")\n",
    "\n",
    "#         # list of all the csv files in the result directory result_dir/inislico/MetFrag/\n",
    "#         files_met = (glob.glob(result+'/*.csv'))\n",
    "\n",
    "#         # read the csv file that contains all the features from the input .mzml file\n",
    "#         file1  = pd.read_csv(input_dir + (input_table['ResultFileNames'][m] + '/insilico/MS1DATA.csv').replace(\"./\", \"\"))\n",
    "    \n",
    "#         # for each feature in the MS1DATA.csv file\n",
    "#         for i, row in file1.iterrows():\n",
    "        \n",
    "#             # take id as a pattern to differentiate between different ids\n",
    "#             pattern = file1.loc[i, \"id_X\"]\n",
    "        \n",
    "#             #check which of the csv result files have the same pattern in their names\n",
    "#             results = [i for i in files_met if pattern in i]\n",
    "        \n",
    "#             # find which of the files with that id have KEGG in their names,\n",
    "#             KEGG = [i for i in results if \"KEGG\" in i]\n",
    "        \n",
    "#             # if kegg present in the name\n",
    "#             if KEGG:\n",
    "            \n",
    "#                 # read the KEGG csv file for that feature\n",
    "#                 KEGG_file = pd.read_csv((KEGG)[0])\n",
    "            \n",
    "#                 # if the KEGG file isn't empty\n",
    "#                 if len(KEGG_file)>0:\n",
    "                \n",
    "#                     # extract only the columns with >0.75 score\n",
    "#                     KEGG_file = KEGG_file.drop(KEGG_file[KEGG_file.Score < 0.98].index)\n",
    "                    \n",
    "#                     #s_best_kg = []\n",
    "#                     #for kg, rows in KEGG_file.iterrows():\n",
    "#                         #kg_smiles = Chem.MolToSmiles(Chem.MolFromInchi(KEGG_file[\"InChI\"][kg]))\n",
    "#                         #SSmsk = [Chem.MolFromSmiles(kg_smiles), Chem.MolFromSmiles(siriusResults[\"SMILES\"][0])]\n",
    "#                         #SSfpsk = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in SSmsk]\n",
    "#                         #SStn2k = DataStructs.FingerprintSimilarity(SSfpsk[0],SSfpsk[1])\n",
    "#                         #s_best_kg.append(SStn2k)\n",
    "#                     #index_kg = np.argmax(s_best_kg)\n",
    "                        \n",
    "#                     # add the relevavnt information to the original MS1DATA csv\n",
    "#                     file1.loc[i, 'KG_ID'] = KEGG_file.loc[0, 'Identifier']\n",
    "#                     file1.loc[i, 'KG_Name'] = KEGG_file.loc[0, 'CompoundName']\n",
    "#                     file1.loc[i, 'KG_Formula'] = KEGG_file.loc[0, 'MolecularFormula']\n",
    "#                     file1.loc[i, 'KG_expPeaks'] = KEGG_file.loc[0, 'NoExplPeaks']\n",
    "#                     file1.loc[i, 'KG_SMILES'] = Chem.MolToSmiles(Chem.MolFromInchi(KEGG_file[\"InChI\"][0]))\n",
    "#                     file1.loc[i, 'KG_Score'] = KEGG_file.loc[0, 'Score']\n",
    "#                     if sl:\n",
    "#                         file1.loc[i, 'KGSL_Score'] = KEGG_file.loc[0, 'SuspectListScore']\n",
    "#                     file1.loc[i, 'KG_file'] = KEGG[0]\n",
    "                \n",
    "#                     #create empty list of KEGG top smiles\n",
    "#                     Kegg_smiles = []\n",
    "                \n",
    "#                     # extract only the InChI of the top 5\n",
    "#                     for j in KEGG_file[\"InChI\"][0:5].tolist():\n",
    "#                         # convert the InChI to SMILES\n",
    "#                         mol = Chem.MolToSmiles(Chem.MolFromInchi(j))\n",
    "#                         mol2 = Chem.MolFromSmiles(mol)\n",
    "#                         Kegg_smiles.append(mol2)\n",
    "#                     # if there are more than 1 top smiles\n",
    "#                     if len(Kegg_smiles) > 1:\n",
    "#                         #calculate the MCSS\n",
    "#                         res = rdFMCS.FindMCS(Kegg_smiles)\n",
    "#                         sm_res = Chem.MolToSmiles(Chem.MolFromSmarts(res.smartsString))\n",
    "#                         # if there are atleast 3 heavy atoms in the MCSS, then add it to the result file\n",
    "#                         elem = [ele for ele in heavy_atoms if(ele in sm_res)]\n",
    "#                         if elem and len(sm_res)>=3:\n",
    "#                             file1.loc[i, 'KG_MCSSstring'] = res.smartsString\n",
    "#                             file1.loc[i, 'KG_MCSS_SMILES'] = Chem.MolToSmiles(Chem.MolFromSmarts(res.smartsString))\n",
    "                            \n",
    "#             #start here for PubChem; find which of the files with that id have PubChem in their names,\n",
    "#             PubChem = [i for i in results if \"PubChem\" in i]\n",
    "            \n",
    "#             if PubChem:\n",
    "\n",
    "#                 PubChem_file = pd.read_csv(PubChem[0])\n",
    "                \n",
    "#                 # if more candidates\n",
    "#                 if len(PubChem_file)>0:\n",
    "                    \n",
    "#                     # take the ones with more than 0.80 score\n",
    "#                     PubChem_file = PubChem_file.drop(PubChem_file[PubChem_file.Score < 0.80].index)\n",
    "#                     #s_best_pb = []\n",
    "#                     #for pb, rows in PubChem_file.iterrows():\n",
    "#                         #SSmsp = [Chem.MolFromSmiles(PubChem_file[\"SMILES\"][pb]), Chem.MolFromSmiles(siriusResults[\"SMILES\"][0])]\n",
    "#                         #SSfpsp = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in SSmsp]\n",
    "#                         #SStn2p = DataStructs.FingerprintSimilarity(SSfpsp[0],SSfpsp[1])\n",
    "#                         #s_best_pb.append(SStn2p)\n",
    "#                     #index_pb = np.argmax(s_best_pb)\n",
    "#                     # add the relavnt information to the original MS1DATA csv\n",
    "#                     file1.loc[i, 'PC_ID'] = PubChem_file.loc[0, 'Identifier']\n",
    "#                     file1.loc[i, 'PC_Name'] = PubChem_file.loc[0, 'IUPACName']\n",
    "#                     file1.loc[i, 'PC_Formula'] = PubChem_file.loc[0, 'MolecularFormula']\n",
    "#                     file1.loc[i, 'PC_expPeaks'] = PubChem_file.loc[0, 'NoExplPeaks']\n",
    "#                     file1.loc[i, 'PC_SMILES'] = PubChem_file[\"SMILES\"][0]\n",
    "#                     file1.loc[i, 'PC_Score'] = PubChem_file[\"Score\"][0]\n",
    "#                     if sl:\n",
    "#                         file1.loc[i, 'PCSL_Score'] = PubChem_file.loc[0, 'SuspectListScore']\n",
    "#                     file1.loc[i, 'PC_file'] = PubChem[0]\n",
    "                    \n",
    "#                     # empty object\n",
    "#                     Pubchem_smiles = []\n",
    "                    \n",
    "#                     # extract only the SMILES of the top 5\n",
    "#                     for j in PubChem_file[\"SMILES\"][0:5].tolist():\n",
    "                        \n",
    "#                         # Concert smiles to mol\n",
    "#                         sm2 = Chem.MolFromSmiles(j)\n",
    "#                         # store mol in Pubchem_smiles\n",
    "#                         Pubchem_smiles.append(sm2)\n",
    "                    \n",
    "#                     if len(Pubchem_smiles) > 1:\n",
    "#                         # calculate MCSS\n",
    "#                         res2 = rdFMCS.FindMCS(Pubchem_smiles)\n",
    "#                         sm_res = Chem.MolToSmiles(Chem.MolFromSmarts(res2.smartsString))\n",
    "#                         # If atleast 3 heavy atoms present\n",
    "#                         elem = [ele for ele in heavy_atoms if(ele in sm_res)]\n",
    "#                         if elem and len(sm_res)>=3:\n",
    "#                             file1.loc[i, 'PC_MCSSstring']= res2.smartsString\n",
    "#                             file1.loc[i, 'PC_MCSS_SMILES'] = Chem.MolToSmiles(Chem.MolFromSmarts(res2.smartsString))\n",
    "#         file1.to_csv(input_dir + (input_table['ResultFileNames'][m] + '/insilico/MetFragResults.csv').replace(\"./\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60516ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine_insilico(input_dir, input_tablecsv, Source = \"all_insilico\"):\n",
    "    \n",
    "#     \"\"\"combine_insilico function combines the Sirius results from all\n",
    "#     result directories for each input mzml file. It does same for \n",
    "#     Metfrag.\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "    \n",
    "#     input_table (str): This is the table in csv format (defined in R), \n",
    "#     which stores a csv table containing columns \"mzml_files\", which \n",
    "#     contains liat of all input files with their relative paths, second\n",
    "#     column is \"ResultFileName\" which is a list of the corresponding\n",
    "#     result relative directories to each mzml files. Lastly, \"file_id\", \n",
    "#     contains a file directory. This table will be used to read the \n",
    "#     Sirius and MetFrag result csv files\n",
    "    \n",
    "#     Source (str): either \"SIRIUS\" or \"MetFrag\"\n",
    "\n",
    "#     Returns:\n",
    "    \n",
    "#     dataframe: of combined SIRIUS/MetFrag results\n",
    "    \n",
    "#     csv: stores the dataframe in a csv, named as \n",
    "#     \"input_dir/ResultFileName/MetabolomicsResults/SIRIUS_combined.csv\" \n",
    "#     OR/AND \n",
    "#     \"input_dir/ResultFileName/MetabolomicsResults/MetFrag_combined.csv\"\n",
    "    \n",
    "    \n",
    "#     Usage:\n",
    "#     combine_insilico(input_dir = \"/user/project/\", \n",
    "#     input_table = \"/user/project/suspectlist.csv\", Source = \"SIRIUS\")\n",
    "\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     input_table = pd.read_csv(input_tablecsv)\n",
    "#     # create a new directory to store all results /MetabolomicsResults/\n",
    "#     path = os.path.join(input_dir, \"MetabolomicsResults\")\n",
    "#     if not os.path.isdir(path):\n",
    "#         os.mkdir(path)    \n",
    "#     # if Sirius results are to be combined\n",
    "#     if Source == \"all_insilico\" or Source == \"SIRIUS\":\n",
    "        \n",
    "#         # store all files paths here\n",
    "#         all_files = []\n",
    "#         for n, row in input_table.iterrows():\n",
    "#             all_files.append(input_dir + input_table['ResultFileNames'][n].replace(\"./\", \"\") + '/insilico/SiriusResults.csv')\n",
    "        \n",
    "#         # store all dataframes of the results here\n",
    "#         li = []\n",
    "    \n",
    "#         for filename in all_files:\n",
    "#             df = pd.read_csv(filename, index_col=None, header=0)\n",
    "#             df[\"ResultFileNames\"] = filename\n",
    "#             li.append(df)\n",
    "            \n",
    "#         # join all resulst dataframe\n",
    "#         frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "#         frame.to_csv(input_dir + '/MetabolomicsResults/SIRIUS_combined.csv')       \n",
    "    \n",
    "#     # if MetFrag results are to be combined\n",
    "#     if Source == \"all_insilico\" or Source == \"MetFrag\":\n",
    "        \n",
    "#         # store all files paths here\n",
    "#         all_files = []\n",
    "#         for m, row in input_table.iterrows():\n",
    "#             all_files.append(input_dir + input_table['ResultFileNames'][m].replace(\"./\", \"\") + '/insilico/MetFragResults.csv')\n",
    "#         li = []\n",
    "\n",
    "#         for filename in all_files:\n",
    "#             df = pd.read_csv(filename, index_col=None, header=0)\n",
    "#             df[\"result_dir\"] = filename\n",
    "#             li.append(df)\n",
    "\n",
    "#         frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "#         frame.to_csv(input_dir+'MetabolomicsResults/MetFrag_combined.csv')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b45722d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine_specdb(input_dir):\n",
    "    \n",
    "#     \"\"\"combine_specdb function combines all results from different\n",
    "#     spectral dbs. Can only be used if more than one db is used \n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "\n",
    "#     Returns:\n",
    "#     dataframe: of the paths of the merged results\n",
    "    \n",
    "    \n",
    "#     Usage:\n",
    "#     combine_specdb(input_dir)\n",
    "\n",
    "#     \"\"\"\n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "\n",
    "    \n",
    "#     # empty lists of csv files paths for each database\n",
    "#     GNPScsvfiles2 = []\n",
    "#     HMDBcsvfiles2 = []\n",
    "#     MassBankcsvfiles2 = []\n",
    "    \n",
    "#     #list all files and directories\n",
    "#     for entry in os.listdir(input_dir):\n",
    "#         if os.path.isdir(os.path.join(input_dir, entry)):\n",
    "            \n",
    "#             # enter the directory with /spectral_dereplication/ results\n",
    "#             sub_dir = input_dir + entry + '/spectral_dereplication'\n",
    "#             if os.path.exists(sub_dir):\n",
    "#                 files = (glob.glob(sub_dir+'/*.csv'))\n",
    "\n",
    "#                 for f in files:\n",
    "#                     if 'gnpsproc.' in f: \n",
    "#                         GNPScsvfiles2.append(f)\n",
    "#                     if 'hmdbproc.' in f: \n",
    "#                         HMDBcsvfiles2.append(f)\n",
    "#                     if 'mbankproc.' in f: \n",
    "#                         MassBankcsvfiles2.append(f)\n",
    "   \n",
    "#     # if all results present\n",
    "#     if len(GNPScsvfiles2)>0 and len(HMDBcsvfiles2)>0 and len(MassBankcsvfiles2)>0:\n",
    "        \n",
    "#         dict1 = {'GNPSr': GNPScsvfiles2, 'HMDBr': HMDBcsvfiles2, 'MBr': MassBankcsvfiles2} \n",
    "#         df = pd.DataFrame(dict1)\n",
    "    \n",
    "#         Merged_Result_df = []\n",
    "#         for i, row in df.iterrows():\n",
    "#             CSVfileG = pd.read_csv(df[\"GNPSr\"][i])\n",
    "#             CSVfileH = pd.read_csv(df[\"HMDBr\"][i])\n",
    "#             CSVfileM = pd.read_csv(df[\"MBr\"][i])\n",
    "#             if os.path.exists(df[\"MBr\"][i]) and os.path.exists(df[\"HMDBr\"][i]) and os.path.exists(df[\"GNPSr\"][i]):\n",
    "#                 # merge on the basis of Idx\n",
    "#                 MergedRE = CSVfileG.merge(CSVfileH,on='id_X').merge(CSVfileM,on='id_X')\n",
    "#                 csvname = (df[\"GNPSr\"][i]).replace(\"gnpsproc\", \"mergedR\")\n",
    "#                 MergedRE.to_csv(csvname)\n",
    "#                 Merged_Result_df.append(csvname)\n",
    "                \n",
    "                \n",
    "#     # if only GNPS and MassBank           \n",
    "#     if len(GNPScsvfiles2)>0 and len(HMDBcsvfiles2)==0 and len(MassBankcsvfiles2)>0:\n",
    "#             dict1 = {'GNPSr': GNPScsvfiles2, 'MBr': MassBankcsvfiles2} \n",
    "#             df = pd.DataFrame(dict1)\n",
    "#             Merged_Result_df = []\n",
    "#             for i, row in df.iterrows():\n",
    "#                 CSVfileG = pd.read_csv(df[\"GNPSr\"][i])\n",
    "#                 CSVfileM = pd.read_csv(df[\"MBr\"][i])\n",
    "#                 if os.path.exists(df[\"MBr\"][i]) and os.path.exists(df[\"GNPSr\"][i]):\n",
    "#                     # merge on the basis of Idx\n",
    "#                     MergedRE = CSVfileG.merge(CSVfileM,on='id_X')\n",
    "#                     csvname = (df[\"MBr\"][i]).replace(\"mbankproc\", \"mergedR\")\n",
    "#                     MergedRE.to_csv(csvname)\n",
    "#                     Merged_Result_df.append(csvname)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#     # if only GNPS and Hmdb\n",
    "#     if not isNaN(GNPScsvfiles2) and not isNaN(HMDBcsvfiles2) and isNaN(MassBankcsvfiles2):\n",
    "#             dict1 = {'GNPSr': GNPScsvfiles2, 'HMDBr': MassBankcsvfiles2} \n",
    "#             df = pd.DataFrame(dict1)\n",
    "#             Merged_Result_df = []\n",
    "#             for i, row in df.iterrows():\n",
    "#                 CSVfileG = pd.read_csv(df[\"GNPSr\"][i])\n",
    "#                 CSVfileH = pd.read_csv(df[\"HMDBr\"][i])\n",
    "#                 if os.path.exists(df[\"HMDBr\"][i]) and os.path.exists(df[\"GNPSr\"][i]):\n",
    "#                     # merge on the basis of Idx\n",
    "#                     MergedRE = CSVfileG.merge(CSVfileH,on='id_X')\n",
    "#                     csvname = (df[\"GNPSr\"][i]).replace(\"gnpsproc\", \"mergedR\")\n",
    "#                     MergedRE.to_csv(csvname)\n",
    "#                     Merged_Result_df.append(csvname)\n",
    "                \n",
    "                \n",
    "                \n",
    "#     # if only MBANK and Hmdb\n",
    "#     if not isNaN(GNPScsvfiles2) and isNaN(HMDBcsvfiles2) and isNaN(MassBankcsvfiles2):\n",
    "#             dict1 = {'GNPSr': GNPScsvfiles2, 'HMDBr': MassBankcsvfiles2} \n",
    "#             df = pd.DataFrame(dict1)   \n",
    "#             dict1 = {'GNPSr': GNPScsvfiles2, 'HMDBr': MassBankcsvfiles2} \n",
    "#             df = pd.DataFrame(dict1)\n",
    "#             Merged_Result_df = []\n",
    "#             for i, row in df.iterrows():\n",
    "#                 CSVfileG = pd.read_csv(df[\"MBr\"][i])\n",
    "#                 CSVfileH = pd.read_csv(df[\"HMDBr\"][i])\n",
    "#                 if os.path.exists(df[\"MBr\"][i]) and os.path.exists(df[\"HMDBr\"][i]):\n",
    "#                     # merge on the basis of Idx\n",
    "#                     MergedRE = CSVfileM.merge(CSVfileH,on='id_X')\n",
    "#                     csvname = (df[\"MBr\"][i]).replace(\"mbankproc\", \"mergedR\")\n",
    "#                     MergedRE.to_csv(csvname)\n",
    "#                     Merged_Result_df.append(csvname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45c9153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine_allspec(input_dir):\n",
    "    \n",
    "#     \"\"\"combine_allspec function combines all results from different\n",
    "#     spectral dbs. Can only be used if more than one db is used \n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "#     df (dataframe): dataframe from combine_specdb\n",
    "    \n",
    "#     Returns:\n",
    "#     dataframe: of the paths of the merged results from all files\n",
    "    \n",
    "#     Usage:\n",
    "#     combine_allspec(input_dir = \"usr/project/\", comb_df)\n",
    "\n",
    "#     \"\"\"\n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "#     # create a new directory to store all results /MetabolomicsResults/\n",
    "#     path = os.path.join(input_dir, \"MetabolomicsResults\")\n",
    "#     if not os.path.isdir(path):\n",
    "#         os.mkdir(path)\n",
    "        \n",
    "        \n",
    "#     Mergedcsvfiles = []\n",
    "#     single_file = []\n",
    "    \n",
    "#     #list all files and directories\n",
    "#     for entry in os.listdir(input_dir):\n",
    "#         if os.path.isdir(os.path.join(input_dir, entry)):\n",
    "            \n",
    "#             # enter the directory with /spectral_dereplication/ results\n",
    "#             sub_dir = input_dir + entry + '/spectral_dereplication'\n",
    "#             if os.path.exists(sub_dir):\n",
    "#                 files = (glob.glob(sub_dir+'/*.csv'))\n",
    "\n",
    "#                 for f in files:\n",
    "#                     if 'mergedR.csv' in f: \n",
    "#                         Mergedcsvfiles.append(f)\n",
    "#                     else:\n",
    "#                         single_file.append(f)\n",
    "    \n",
    "#     if len(Mergedcsvfiles)>0:\n",
    "#         combined_csv = pd.concat([pd.read_csv(l) for l in Mergedcsvfiles], ignore_index=True)\n",
    "#         combined_csv.to_csv(input_dir + 'MetabolomicsResults/SD_post_processed_combined_results.csv')\n",
    "#         return(combined_csv)\n",
    "#     else:\n",
    "#         single_csv = pd.read_csv(single_file[0])\n",
    "#         single_csv.to_csv(input_dir + 'MetabolomicsResults/SD_post_processed_combined_results.csv')\n",
    "#         return(single_csv)\n",
    "    \n",
    "#     #for i, row in combined_csv.iterrows():\n",
    "#         #if combined_csv['GNPSSMILES'][i] == ' ' or isNaN(combined_csv['GNPSSMILES'][i]):\n",
    "#             #combined_csv['GNPSSMILES'][i] = ''\n",
    "            \n",
    "#     #for i, row in combined_csv.iterrows():\n",
    "#         #if not isNaN(combined_csv['MBinchiKEY'][i]):\n",
    "#             #try:\n",
    "#                 #y = pcp.get_compounds(combined_csv['MBinchiKEY'][i], 'inchikey')\n",
    "#                 #if len(y)>1:\n",
    "#                     #combined_csv['MBSMILES'][i] = y[0].isomeric_smiles\n",
    "#             #except:\n",
    "#                 #pass\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23cf8017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scoring_spec(input_dir, spec_file):\n",
    "    \n",
    "#     \"\"\"scoring_spec extracts the candidates with high scores from\n",
    "#     the results from combine_allspec function \n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "#     combined (dataframe): dataframe from combine_allspec\n",
    "    \n",
    "#     Returns:\n",
    "#     dataframe: of the all features and their results\n",
    "#     csv: CSV reuslt file named MetabolomicsResults/combinedSpecDB.csv\n",
    "#     which contains all the features and their Spec DB annotations\n",
    "    \n",
    "#     Usage:\n",
    "#     scoring_spec(input_dir = \"usr/project/\", combined)\n",
    "\n",
    "#     \"\"\"\n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "#     # the scoring highly depends on the following information:\n",
    "#     # similarity scores should be higher than 0.75\n",
    "#     # intScore >=0.50\n",
    "#     # mzScore >= 0.50\n",
    "#     # ratio of the matchingpeaks by the totalpeaks in the query >= 0.50\n",
    "    \n",
    "#     combined = pd.read_csv(spec_file)\n",
    "    \n",
    "#     def HMDB_Scoring(db, i):\n",
    "#         if db['HMDBmax_similarity'][i] >= 0.75 and db['HMDBintScore'][i] >= 0.50 and db['HMDBmzScore'][i] >= 0.50 and db['HQMatchingPeaks'][i]/db['hQueryTotalPeaks'][i] >= 0.50:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "    \n",
    "    \n",
    "#     def GNPS_Scoring(db, i):\n",
    "#         if db['GNPSmax_similarity'][i] >= 0.90 and db['GNPSintScore'][i] >= 0.50 and db['GNPSmzScore'][i] >= 0.50 and db['GQMatchingPeaks'][i]/db['gQueryTotalPeaks'][i] >= 0.50:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "    \n",
    "    \n",
    "#     def MB_Scoring(db, i):\n",
    "#         if db['MBmax_similarity'][i] >= 0.50 and db['MBintScore'][i] >= 0.50 and db['MBmzScore'][i] >= 0.50 and db['MQMatchingPeaks'][i]/db['mQueryTotalPeaks'][i] >= 0.50:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "    \n",
    "    \n",
    "#     for i, row in combined.iterrows():\n",
    "        \n",
    "        \n",
    "#         if 'HMDBSMILES' in combined.columns and 'MBSMILES' in combined.columns and 'GNPSSMILES' in combined.columns:\n",
    "            \n",
    "#             # if all DBs show good candidates accorindg to the scoring\n",
    "#             if HMDB_Scoring(combined, i) and GNPS_Scoring(combined, i) and MB_Scoring(combined, i) and not isNaN(combined['GNPSSMILES'][i]) and not isNaN(combined['MBSMILES'][i]) and not isNaN(combined['HMDBSMILES'][i]):\n",
    "            \n",
    "#                 # calulate the tanimoto similarity between the candidates from three DBs\n",
    "            \n",
    "#                 # hmdb and gnps\n",
    "#                 HGms = [Chem.MolFromSmiles(combined['HMDBSMILES'][i]), Chem.MolFromSmiles(combined['GNPSSMILES'][i])]\n",
    "#                 HGfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in HGms]\n",
    "#                 HGtn = DataStructs.FingerprintSimilarity(HGfps[0],HGfps[1])\n",
    "            \n",
    "#                 # gnps and mbank\n",
    "#                 GMms = [Chem.MolFromSmiles(combined['GNPSSMILES'][i]), Chem.MolFromSmiles(combined['MBSMILES'][i])]\n",
    "#                 GMfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in GMms]\n",
    "#                 GMtn = DataStructs.FingerprintSimilarity(GMfps[0],GMfps[1])\n",
    "            \n",
    "#                 # mbank and hmdb\n",
    "#                 HMms = [Chem.MolFromSmiles(combined['HMDBSMILES'][i]), Chem.MolFromSmiles(combined['MBSMILES'][i])]\n",
    "#                 HMfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in HMms]\n",
    "#                 HMtn = DataStructs.FingerprintSimilarity(HMfps[0],HMfps[1])\n",
    "            \n",
    "#                 # add the following columns\n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB, GNPS, MassBank'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = HGtn\n",
    "#                 combined.loc[i, 'tanimotoGM'] = GMtn\n",
    "#                 combined.loc[i, 'tanimotoHM'] = HMtn\n",
    "#                 combined.loc[i, 'occurence'] = 3\n",
    "        \n",
    "#             # if HMDB and GNPS show good candidates accorindg to the scoring\n",
    "#             if HMDB_Scoring(combined, i) and GNPS_Scoring(combined, i) and not MB_Scoring(combined, i) and not isNaN(combined['GNPSSMILES'][i]) and not isNaN(combined['HMDBSMILES'][i]):\n",
    "#                 HGms = [Chem.MolFromSmiles(combined['HMDBSMILES'][i]), Chem.MolFromSmiles(combined['GNPSSMILES'][i])]\n",
    "#                 HGfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in HGms]\n",
    "#                 HGtn = DataStructs.FingerprintSimilarity(HGfps[0],HGfps[1])\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB, GNPS'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = HGtn\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 2\n",
    "        \n",
    "#             # if MassBank and GNPS show good candidates accorindg to the scoring\n",
    "#             if not HMDB_Scoring(combined, i) and GNPS_Scoring(combined, i) and MB_Scoring(combined, i) and not isNaN(combined['MBSMILES'][i]) and not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                 GMms = [Chem.MolFromSmiles(combined['GNPSSMILES'][i]), Chem.MolFromSmiles(combined['MBSMILES'][i])]\n",
    "#                 GMfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in GMms]\n",
    "#                 GMtn = DataStructs.FingerprintSimilarity(GMfps[0],GMfps[1])\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'GNPS, MassBank'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoGM'] = GMtn\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 2\n",
    "        \n",
    "#             # if MassBank and HMDB show good candidates accorindg to the scoring\n",
    "#             if HMDB_Scoring(combined, i) and not GNPS_Scoring(combined, i) and MB_Scoring(combined, i) and not isNaN(combined['MBSMILES'][i]) and not isNaN(combined['HMDBSMILES'][i]):\n",
    "#                 HMms = [Chem.MolFromSmiles(combined['HMDBSMILES'][i]), Chem.MolFromSmiles(combined['MBSMILES'][i])]\n",
    "#                 HMfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in HMms]\n",
    "#                 HMtn = DataStructs.FingerprintSimilarity(HMfps[0],HMfps[1])\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB, MassBank'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoHM'] = HMtn\n",
    "#                 combined.loc[i, 'occurence'] = 2\n",
    "        \n",
    "#             # only HMDB\n",
    "#             if HMDB_Scoring(combined, i) and not GNPS_Scoring(combined, i) and not MB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "            \n",
    "#             # only GNPS\n",
    "#             if not HMDB_Scoring(combined, i) and GNPS_Scoring(combined, i) and not MB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'GNPS'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "        \n",
    "#             # only MassBank\n",
    "#             if not HMDB_Scoring(combined, i) and not GNPS_Scoring(combined, i) and MB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'MassBank'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "        \n",
    "#             # none\n",
    "#             if not HMDB_Scoring(combined, i) and not GNPS_Scoring(combined, i) and not MB_Scoring(combined, i):\n",
    "#                 combined.loc[i, 'annotation'] = 'none'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 0\n",
    "        \n",
    "#         if 'HMDBSMILES' not in combined.columns and 'MBSMILES' in combined.columns and 'GNPSSMILES' in combined.columns:\n",
    "\n",
    "#             # if MassBank and GNPS show good candidates accorindg to the scoring\n",
    "#             if GNPS_Scoring(combined, i) and MB_Scoring(combined, i) and not isNaN(combined['MBSMILES'][i]) and not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                 GMms = [Chem.MolFromSmiles(combined['GNPSSMILES'][i]), Chem.MolFromSmiles(combined['MBSMILES'][i])]\n",
    "#                 GMfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in GMms]\n",
    "#                 GMtn = DataStructs.FingerprintSimilarity(GMfps[0],GMfps[1])\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'GNPS, MassBank'\n",
    "#                 combined.loc[i, 'tanimotoGM'] = GMtn\n",
    "#                 combined.loc[i, 'occurence'] = 2\n",
    "#             # only GNPS\n",
    "#             if GNPS_Scoring(combined, i) and not MB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'GNPS'\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "        \n",
    "#             # only MassBank\n",
    "#             if not GNPS_Scoring(combined, i) and MB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'MassBank'\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "                \n",
    "#             # none\n",
    "#             if not GNPS_Scoring(combined, i) and not MB_Scoring(combined, i):\n",
    "#                 combined.loc[i, 'annotation'] = 'none'\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 0\n",
    "                \n",
    "                \n",
    "                \n",
    "#         if 'HMDBSMILES' in combined.columns and 'MBSMILES' not in combined.columns and 'GNPSSMILES' in combined.columns:\n",
    "#             # if HMDB and GNPS show good candidates accorindg to the scoring\n",
    "#             if HMDB_Scoring(combined, i) and GNPS_Scoring(combined, i) and not isNaN(combined['GNPSSMILES'][i]) and not isNaN(combined['HMDBSMILES'][i]):\n",
    "#                 HGms = [Chem.MolFromSmiles(combined['HMDBSMILES'][i]), Chem.MolFromSmiles(combined['GNPSSMILES'][i])]\n",
    "#                 HGfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in HGms]\n",
    "#                 HGtn = DataStructs.FingerprintSimilarity(HGfps[0],HGfps[1])\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB, GNPS'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = HGtn\n",
    "#                 combined.loc[i, 'occurence'] = 2\n",
    "        \n",
    "#             # only HMDB\n",
    "#             if HMDB_Scoring(combined, i) and not GNPS_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "            \n",
    "#             # only GNPS\n",
    "#             if not HMDB_Scoring(combined, i) and GNPS_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'GNPS'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "#             # none\n",
    "#             if not HMDB_Scoring(combined, i) and not GNPS_Scoring(combined, i):\n",
    "#                 combined.loc[i, 'annotation'] = 'none'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 0\n",
    "    \n",
    "#         if 'HMDBSMILES' in combined.columns and 'MBSMILES' in combined.columns and 'GNPSSMILES' not in combined.columns:\n",
    "            \n",
    "#             # if MassBank and HMDB show good candidates accorindg to the scoring\n",
    "#             if HMDB_Scoring(combined, i) and MB_Scoring(combined, i) and not isNaN(combined['MBSMILES'][i]) and not isNaN(combined['HMDBSMILES'][i]):\n",
    "#                 HMms = [Chem.MolFromSmiles(combined['HMDBSMILES'][i]), Chem.MolFromSmiles(combined['MBSMILES'][i])]\n",
    "#                 HMfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in HMms]\n",
    "#                 HMtn = DataStructs.FingerprintSimilarity(HMfps[0],HMfps[1])\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB, MassBank'\n",
    "#                 combined.loc[i, 'tanimotoHM'] = HMtn\n",
    "#                 combined.loc[i, 'occurence'] = 2\n",
    "                \n",
    "#             # only HMDB\n",
    "#             if HMDB_Scoring(combined, i) and not MB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB'\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "            \n",
    "#             # only MassBank\n",
    "#             if not HMDB_Scoring(combined, i) and MB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'MassBank'\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "        \n",
    "#             # none\n",
    "#             if not HMDB_Scoring(combined, i) and not MB_Scoring(combined, i):\n",
    "#                 combined.loc[i, 'annotation'] = 'none'\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 0\n",
    "        \n",
    "        \n",
    "#         #If only HMDB was used\n",
    "        \n",
    "#         if 'HMDBSMILES' in combined.columns and 'MBSMILES' not in combined.columns and 'GNPSSMILES' not in combined.columns:\n",
    "#             # only HMDB\n",
    "#             if HMDB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB'\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "            \n",
    "#             # none\n",
    "#             if not HMDB_Scoring(combined, i):\n",
    "#                 combined.loc[i, 'annotation'] = 'none'\n",
    "#                 combined.loc[i, 'occurence'] = 0\n",
    "                \n",
    "                \n",
    "#         #If only MassBank was used      \n",
    "                \n",
    "#         if 'HMDBSMILES' not in combined.columns and 'MBSMILES' in combined.columns and 'GNPSSMILES' not in combined.columns:\n",
    "#             # only MassBank\n",
    "#             if MB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'MassBank'\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "            \n",
    "#             # none\n",
    "#             if not MB_Scoring(combined, i):\n",
    "#                 combined.loc[i, 'annotation'] = 'none'\n",
    "#                 combined.loc[i, 'occurence'] = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "#         #If only GNPS was used\n",
    "        \n",
    "#         if 'HMDBSMILES' not in combined.columns and 'MBSMILES' not in combined.columns and 'GNPSSMILES' in combined.columns:\n",
    "#             # only GNPS\n",
    "#             if GNPS_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'GNPS'\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "            \n",
    "#             # none\n",
    "#             if not GNPS_Scoring(combined, i):\n",
    "#                 combined.loc[i, 'annotation'] = 'none'\n",
    "#                 combined.loc[i, 'occurence'] = 0\n",
    "                \n",
    "                \n",
    "#     combined.to_csv(input_dir + \"MetabolomicsResults/scoredSpecDB.csv\")\n",
    "#     return(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "967edbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def metfrag_curation(input_dir, metfragcsv, sl = True):\n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "    \n",
    "#     \"\"\"metfrag_curation checks which database produced results. If both \n",
    "#     did, it checks whether it was the same compound as candidate, if not,\n",
    "#     add PubChem or any of the two databases with similarity to Suspect\n",
    "#     list\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "#     metfragcsv (str): path to combined metfrag results:\n",
    "#     MetabolomicsResults/MetFrag_combined.csv\n",
    "    \n",
    "#     Returns:\n",
    "#     dataframe: dataframe of curated metfrag results\n",
    "#     csv: MetabolomicsResults/metfrag_curated.csv\n",
    "    \n",
    "#     Usage:\n",
    "#     metfrag_curation(input_dir = \"usr/project/\", \n",
    "#     metfragcsv = \"usr/project/MetabolomicsResults/MetFrag_combined.csv\")\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     metfrag = pd.read_csv(metfragcsv)\n",
    "#     for i, row in metfrag.iterrows():\n",
    "        \n",
    "        \n",
    "#         # If only KEGG\n",
    "#         if not isNaN(metfrag['KG_SMILES'][i]) and isNaN(metfrag['PC_SMILES'][i]):\n",
    "#             metfrag.loc[i, 'Annotation_M'] = 'KEGG'\n",
    "#             if sl:\n",
    "#                 if metfrag['KGSL_Score'][i]>=0.9:\n",
    "#                     metfrag.loc[i, 'Annotation_M'] = 'KEGG, SuspectList'\n",
    "#                 else:\n",
    "#                     metfrag.loc[i, 'Annotation_M'] = 'KEGG'\n",
    "    \n",
    "#         # If only Pubchem\n",
    "#         if not isNaN(metfrag['PC_SMILES'][i]) and isNaN(metfrag['KG_SMILES'][i]):\n",
    "#             metfrag.loc[i, 'Annotation_M'] = 'PubChem'\n",
    "#             if sl:\n",
    "#                 if metfrag['PCSL_Score'][i]>=0.9:\n",
    "#                     metfrag.loc[i, 'Annotation_M'] = 'PubChem, SuspectList'\n",
    "#                 else:\n",
    "#                     metfrag.loc[i, 'Annotation_M'] = 'PubChem'           \n",
    "        \n",
    "    \n",
    "#         # If both, calculate the similarity\n",
    "#         if not isNaN(metfrag['PC_SMILES'][i]) and not isNaN(metfrag['KG_SMILES'][i]):\n",
    "        \n",
    "#             PKms = [Chem.MolFromSmiles(metfrag['KG_SMILES'][i]), Chem.MolFromSmiles(metfrag['PC_SMILES'][i])]\n",
    "#             PKfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in PKms]\n",
    "#             PKtn = DataStructs.FingerprintSimilarity(PKfps[0],PKfps[1])\n",
    "        \n",
    "#             # if both are similar, add both\n",
    "#             if PKtn == 1:\n",
    "#                 metfrag.loc[i, 'Annotation_M'] = 'KEGG, PubChem'\n",
    "#                 if sl:\n",
    "#                     if metfrag['KGSL_Score'][i]>=0.9 and metfrag['PCSL_Score'][i]>=0.9:\n",
    "#                         metfrag.loc[i, 'Annotation_M'] = metfrag['Annotation_M'][i] + \", SuspectList\"\n",
    "        \n",
    "#             # if not similar:\n",
    "#             # check Suspect list score and Fragmenter Score\n",
    "            \n",
    "#             else:\n",
    "#                 if not isNaN(metfrag[\"KG_Score\"][i]):\n",
    "#                     metfrag.loc[i, 'Annotation_M'] = 'KEGG'\n",
    "#                 else:\n",
    "#                     metfrag.loc[i, 'Annotation_M'] = 'PubChem'\n",
    "                    \n",
    "                                \n",
    "#     metfrag.to_csv(input_dir + \"MetabolomicsResults/metfrag_curated.csv\")  \n",
    "#     return(metfrag)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e805982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sirius_curation(input_dir, siriuscsv, sl = True):\n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "#     \"\"\"sirius_curation checks if candidate selected has a good score for \n",
    "#     explained intensity. It also checks if there was any similarity to\n",
    "#     a compound from Suspect list\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "#     siriuscsv (str): path to combined metfrag results:\n",
    "#     MetabolomicsResults/Sirius_combined.csv\n",
    "    \n",
    "#     Returns:\n",
    "#     dataframe: dataframe of curated sirius results\n",
    "#     csv: MetabolomicsResults/sirius_curated.csv\n",
    "    \n",
    "#     Usage:\n",
    "#     sirius_curation(input_dir = \"usr/project/\", \n",
    "#     siriuscsv = \"usr/project/MetabolomicsResults/Sirius_combined.csv\")\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     sirius = pd.read_csv(siriuscsv)\n",
    "#     for i, row in sirius.iterrows():\n",
    "    \n",
    "#         # If the explained intensity is greater than 0.70 and there is no suspect list entry\n",
    "#         if sirius['exp_int'][i] >= 0.70 and \"SIRIUS_SL\" not in sirius['Result'][i]:\n",
    "#             sirius.loc[i, 'Annotation_S'] = 'SIRIUS'\n",
    "#             #sirius.loc[i, 'SMILES_final'] = sirius['SMILES'][i]\n",
    "#         else:\n",
    "#             if sl:\n",
    "                \n",
    "#                 #If the explained intensity is greater than 0.70 and there is an entry from suspect list\n",
    "#                 if sirius['exp_int'][i] >= 0.70 and \"SIRIUS_SL\" in sirius['Result'][i]:\n",
    "#                     sirius.loc[i, 'Annotation_S'] = 'SIRIUS, SuspectList'\n",
    "#                     #sirius.loc[i, 'SMILES_final'] = sirius['SMILES'][i]\n",
    "    \n",
    "#                 # if the intensity is less thna 0.70 but it still is similar to an entry in Suspect list,\n",
    "#                 elif sirius['exp_int'][i] < 0.70 and \"SIRIUS_SL\" in sirius['Result'][i]:\n",
    "#                     sirius.loc[i, 'Annotation_S'] = 'SIRIUS, SuspectList'\n",
    "#                     #sirius.loc[i, 'SMILES_final'] = sirius['SMILES'][i]\n",
    "        \n",
    "#     sirius.to_csv(input_dir + \"MetabolomicsResults/sirius_curated.csv\")\n",
    "#     return(sirius)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5a4424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combineSM(input_dir, metfragcsv, siriuscsv):\n",
    "    \n",
    "#     \"\"\"combineSM prioritizes Sirius and Suspect list over PubChem and\n",
    "#     KEGG\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "#     sirius (dataframe): result of sirius_curation\n",
    "#     metfrag (dataframe): result of metfrag_curation\n",
    "    \n",
    "#     Returns:\n",
    "#     dataframe: dataframe of combined curated sirius and metfrag results\n",
    "#     csv: \"MetabolomicsResults/combinedSM.csv\"\n",
    "    \n",
    "#     Usage:\n",
    "#     combineSM(input_dir = \"usr/project/\", metfrag, sirius)\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "    \n",
    "#     metfrag = pd.read_csv(metfragcsv)\n",
    "#     sirius = pd.read_csv(siriuscsv)\n",
    "#     S_M_CSV = pd.concat([sirius, metfrag], axis = 1, levels = [\"id_X\"])\n",
    "    \n",
    "#     for i, rows in S_M_CSV.iterrows():\n",
    "#         # if results has Sirius Structure annotation, and the explained inetnsity is >= 0.70, keep the annotation as is.\n",
    "#         if S_M_CSV[\"Result\"][i] == \"SIRIUS_STR\" and S_M_CSV['exp_int'][i] >= 0.70:\n",
    "#             S_M_CSV.loc[i, 'Annotation_C'] = S_M_CSV['Annotation_S'][i]\n",
    "            \n",
    "#             # to add to that annotation\n",
    "#             if not isNaN(S_M_CSV[\"Annotation_M\"][i]):\n",
    "#                 # if annotation has PubChem, by default add SIRIUS\n",
    "#                 if S_M_CSV[\"Annotation_M\"][i] == \"KEGG\":\n",
    "#                     SKms = [Chem.MolFromSmiles(S_M_CSV['SMILES'][i]), Chem.MolFromSmiles(S_M_CSV['KG_SMILES'][i])]\n",
    "#                     SKfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in SKms]\n",
    "#                     SKtn = DataStructs.FingerprintSimilarity(SKfps[0],SKfps[1])\n",
    "\n",
    "#                     if SKtn >= 0.75:\n",
    "\n",
    "#                         S_M_CSV.loc[i, 'Annotation_C'] = S_M_CSV['Annotation_S'][i] +', KEGG'\n",
    "\n",
    "#                     else:\n",
    "#                         S_M_CSV.loc[i, 'Annotation_C'] = S_M_CSV['Annotation_S'][i]\n",
    "                        \n",
    "#                 # if annotation has PubChem, by default add SIRIUS\n",
    "#                 if S_M_CSV[\"Annotation_M\"][i] == \"PubChem\":\n",
    "#                     PSms = [Chem.MolFromSmiles(S_M_CSV['SMILES'][i]), Chem.MolFromSmiles(S_M_CSV['PC_SMILES'][i])]\n",
    "#                     PSfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in PSms]\n",
    "#                     PStn = DataStructs.FingerprintSimilarity(PSfps[0],PSfps[1])\n",
    "\n",
    "#                     # if similar strcutres, then add Pubchme and sirius\n",
    "#                     if PStn >= 0.7:\n",
    "\n",
    "#                         S_M_CSV.loc[i, 'Annotation_C'] = S_M_CSV['Annotation_S'][i] + ', PubChem'\n",
    "\n",
    "#                     # if not then just keep sirius\n",
    "#                     else:\n",
    "#                         S_M_CSV.loc[i, 'Annotation_C'] = S_M_CSV['Annotation_S'][i]\n",
    "                        \n",
    "                        \n",
    "#                 if S_M_CSV[\"Annotation_M\"][i] == \"KEGG, PubChem\":\n",
    "#                     SKms = [Chem.MolFromSmiles(S_M_CSV['SMILES'][i]), Chem.MolFromSmiles(S_M_CSV['KG_SMILES'][i])]\n",
    "#                     SKfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in SKms]\n",
    "#                     SKtn = DataStructs.FingerprintSimilarity(SKfps[0],SKfps[1])\n",
    "#                     if SKtn >= 0.7:\n",
    "\n",
    "#                         S_M_CSV.loc[i, 'Annotation_C'] = S_M_CSV['Annotation_S'][i] +', KEGG, PubChem'\n",
    "\n",
    "#                     else:\n",
    "#                         S_M_CSV.loc[i, 'Annotation_C'] = S_M_CSV['Annotation_S'][i]\n",
    "#     S_M_CSV.to_csv(input_dir + \"MetabolomicsResults/combinedSM.csv\")\n",
    "#     return(S_M_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac35fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mawRpy)",
   "language": "python",
   "name": "mawrpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
