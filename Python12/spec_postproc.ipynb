{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab22885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "#!/usr/bin/env python\n",
    "#make executable in bash chmod +x PyRun\n",
    "\n",
    "# Libraries\n",
    "\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from pandas import json_normalize\n",
    "\n",
    "\n",
    "\n",
    "def spec_postproc(input_dir, Source = \"all\"):\n",
    "    \n",
    "    \"\"\"spec_postproc function processes the resulst from dereplication \n",
    "    using different spectral DBs. \n",
    "\n",
    "    Parameters:\n",
    "    input_dir (str): This is the input directory where all the .mzML \n",
    "    files and their respective result directories are stored.\n",
    "    \n",
    "    Source (str): either \"mbank\" or \"hmdb\" or \"gnps\", or \"all\"\n",
    "\n",
    "    Returns:\n",
    "    \n",
    "    dataframe: of the paths of the processed DB results\n",
    "    \n",
    "    \n",
    "    Usage:\n",
    "    spec_postproc(input_dir = \"/user/project/\", Source = \"all\")\n",
    "\n",
    "    \"\"\"\n",
    "    def isNaN(string):\n",
    "        return string != string\n",
    "\n",
    "    # empty lists of csv files paths for each database\n",
    "    GNPScsvfiles = []\n",
    "    HMDBcsvfiles = []\n",
    "    MassBankcsvfiles = []\n",
    "    \n",
    "    #list all files and directories\n",
    "    for entry in os.listdir(input_dir):\n",
    "        if os.path.isdir(os.path.join(input_dir, entry)):\n",
    "            \n",
    "            # enter the directory with /spectral_dereplication/ results\n",
    "            sub_dir = input_dir + entry + '/spectral_dereplication'\n",
    "            if os.path.exists(sub_dir):\n",
    "                files = (glob.glob(sub_dir+'/*.csv'))\n",
    "\n",
    "                for f in files:\n",
    "                    if 'gnps.' in f: \n",
    "                        GNPScsvfiles.append(f)\n",
    "                    if 'hmdb.' in f: \n",
    "                        HMDBcsvfiles.append(f)\n",
    "                    if 'mbank.' in f: \n",
    "                        MassBankcsvfiles.append(f)\n",
    "                            \n",
    "    \n",
    "    if Source == \"hmdb\" or \"all\":\n",
    "        #download SDF structures\n",
    "        #os.system(\"wget https://hmdb.ca/system/downloads/current/structures.zip\")\n",
    "        #os.system(\"unzip \"+ input_dir + \"structures.zip\")\n",
    "            \n",
    "        # Load the sdf\n",
    "        dframe = PandasTools.LoadSDF((input_dir+\"structures.sdf\"),\n",
    "                                     idName='HMDB_ID',smilesName='SMILES',\n",
    "                                     molColName='Molecule', includeFingerprints=False)\n",
    "        \n",
    "        #### read sdf file from HMDB to collect names and smiles ####\n",
    "    \n",
    "        #HMDB CSV Result file pre_processing\n",
    "        \n",
    "        #open another csv path holding empty list, which will be filled \n",
    "        #with post processed csv results\n",
    "        HMDBcsvfiles2 = []\n",
    "        \n",
    "        for k in HMDBcsvfiles:\n",
    "            \n",
    "            # read the csv files\n",
    "            hmdb_df = pd.read_csv(k)\n",
    "            \n",
    "            # merge on basis of id, frame and hmdb result files\n",
    "            SmilesHM = pd.merge(hmdb_df, dframe, left_on=hmdb_df.HMDBcompoundID, right_on=dframe.DATABASE_ID)\n",
    "            \n",
    "            \n",
    "            for i, row in hmdb_df.iterrows():\n",
    "                \n",
    "                for j, row in SmilesHM.iterrows():\n",
    "                    \n",
    "                    # where index for both match, add the name and SMILES\n",
    "                    if hmdb_df['id_X'][i]== SmilesHM['id_X'][j]:\n",
    "                        hmdb_df.loc[i, 'HMDBSMILES'] = SmilesHM['SMILES'][j]#add SMILES\n",
    "                        hmdb_df.loc[i, 'HMDBcompound_name'] = SmilesHM[\"GENERIC_NAME\"][j]#add name\n",
    "                        hmdb_df.loc[i, 'HMDBformula'] = SmilesHM[\"FORMULA\"][j]#add formula\n",
    "                \n",
    "            csvname = (os.path.splitext(k)[0])+\"proc\"+\".csv\" # name for writing it in a new file\n",
    "            hmdb_df.to_csv(csvname) #write\n",
    "            HMDBcsvfiles2.append(csvname)# add to a list\n",
    "        \n",
    "    #MassBank CSV Result file pre_processing\n",
    "    \n",
    "    if Source == \"mbank\" or \"all\":\n",
    "        \n",
    "        #open another csv path holding empty list, which will be filled \n",
    "        #with post processed csv results\n",
    "        MassBankcsvfiles2 = []\n",
    "        \n",
    "        for l in MassBankcsvfiles:\n",
    "            \n",
    "            # read mbank csv file\n",
    "            mbank_df = pd.read_csv(l)\n",
    "            \n",
    "            for i, row in mbank_df.iterrows():\n",
    "                \n",
    "                inchiK = str(mbank_df[\"MBinchiKEY\"][i])\n",
    "                \n",
    "                #extract inchikeys\n",
    "                y = pcp.get_compounds(inchiK, 'inchikey')#compound based on inchikey\n",
    "                \n",
    "                for compound in y:\n",
    "                    \n",
    "                    #add smiles\n",
    "                    smles = compound.isomeric_smiles   \n",
    "                    mbank_df.loc[i, 'MBSMILES'] = smles\n",
    "                    \n",
    "            csvname = (os.path.splitext(l)[0])+\"proc\"+\".csv\"\n",
    "            mbank_df.to_csv(csvname)\n",
    "            MassBankcsvfiles2.append(csvname)\n",
    "    \n",
    "    # GNPS CSV Result file pre_processing\n",
    "    if Source == \"gnps\" or \"all\":\n",
    "        \n",
    "        #currently only these subsets are removed from the names from GNPS\n",
    "        matches = [\"M+\",\"[M\", \"M-\", \"2M\", \"M*\" \"20.0\", \"50.0\", \"30.0\", \"40.0\", \"60.0\", \"70.0\", \"eV\", \"Massbank\"\n",
    "               , \"Spectral\", \"Match\", \"to\", \"from\", \"NIST14\", \"MoNA\", '[IIN-based:',  '[IIN-based', 'on:', 'CCMSLIB00003136269]']\n",
    "        \n",
    "        #open another csv path holding empty list, which will be filled \n",
    "        #with post processed csv results\n",
    "        GNPScsvfiles2 = []\n",
    "        \n",
    "        for l in GNPScsvfiles:\n",
    "            \n",
    "            gnps_df = pd.read_csv(l)\n",
    "    \n",
    "            for i, row in gnps_df.iterrows():\n",
    "            \n",
    "                # if compound name is present\n",
    "                if not isNaN(gnps_df['GNPScompound_name'][i]):\n",
    "                    \n",
    "                    # split if there is a gap in the names\n",
    "                    string_chng = (gnps_df['GNPScompound_name'][i].split(\" \"))\n",
    "                    \n",
    "                    # create an empty list\n",
    "                    newstr = []\n",
    "                    \n",
    "                    # for each part of the string in the names\n",
    "                    chng = []\n",
    "                    \n",
    "                    for j in range(len(string_chng)):\n",
    "                        \n",
    "                        # check if the substrings re present in the matches and no - is present\n",
    "                        if not any(x in string_chng[j] for x in matches) and not '-' == string_chng[j]:\n",
    "                            \n",
    "                            # IF | and ! not in the substring\n",
    "                            if '|' not in string_chng[j] or '!' not in string_chng[j]:\n",
    "                                newstr.append(string_chng[j])\n",
    "                                \n",
    "                            # if | present in the substring   \n",
    "                            elif '|' in string_chng[j]:\n",
    "                                \n",
    "                                #split the string\n",
    "                                jlen = string_chng[j].split(\"|\")\n",
    "                                #how many substrings are left now\n",
    "                                lst = len(jlen)-1\n",
    "                                #append this to chng\n",
    "                                chng.append(jlen[lst])\n",
    "                                break\n",
    "                                \n",
    "                    # now append chng to newstr            \n",
    "                    chng.append(' '.join(newstr))\n",
    "                    #save this as the correct name\n",
    "                    gnps_df.loc[i, \"corr_names\"] = chng[0]\n",
    "                    \n",
    "                    if not isNaN(gnps_df['GNPSSMILES'][i]):\n",
    "                        if chng == '':\n",
    "                            break\n",
    "                        elif gnps_df['GNPSSMILES'][i].isalpha():\n",
    "                            s = pcp.get_compounds(chng[0], 'name')\n",
    "                            if s:\n",
    "                                for comp in s:\n",
    "                                    gnps_df[\"GNPSSMILES\"][i] = comp.isomeric_smiles\n",
    "                            else:\n",
    "                                gnps_df[\"GNPSSMILES\"][i] = ''\n",
    "                else:\n",
    "                    gnps_df[\"GNPSSMILES\"][i] = ''\n",
    "                    \n",
    "            for i, row in gnps_df.iterrows():\n",
    "                if not isNaN(gnps_df['GNPSSMILES'][i]):\n",
    "                    try:\n",
    "                        sx = pcp.get_compounds(gnps_df['GNPSSMILES'][i], 'smiles')\n",
    "                        if sx:\n",
    "                            sx = str(sx)\n",
    "                            comp = pcp.Compound.from_cid([int(x) for x in re.findall(r'\\b\\d+\\b', sx)])\n",
    "                            gnps_df.loc[i, 'GNPSformula'] = comp.molecular_formula\n",
    "                    except:\n",
    "                        gnps_df.loc[i, 'GNPSformula'] = ''\n",
    "                        \n",
    "            csvname = (os.path.splitext(l)[0])+\"_with_cor_names\"+\".csv\"\n",
    "            gnps_df.to_csv(csvname)\n",
    "            GNPScsvfiles2.append(csvname)\n",
    "    \n",
    "\n",
    "    if Source == \"all\":\n",
    "        \n",
    "        dict1 = {'GNPSr': GNPScsvfiles2, 'HMDBr': HMDBcsvfiles2, 'MBr': MassBankcsvfiles2} \n",
    "        df = pd.DataFrame(dict1)\n",
    "\n",
    "        return(df)\n",
    "\n",
    "spec_postproc(sys.argv[1], sys.argv[2])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mawRpy)",
   "language": "python",
   "name": "mawrpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
