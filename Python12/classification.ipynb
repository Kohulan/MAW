{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d661546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "#!/usr/bin/env python\n",
    "#make executable in bash chmod +x PyRun\n",
    "\n",
    "# Libraries\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import sys\n",
    "\n",
    "import csv \n",
    "import time\n",
    "import json\n",
    "\n",
    "import pubchempy as pcp\n",
    "import numpy as np\n",
    "from pandas import json_normalize\n",
    "\n",
    "from pybatchclassyfire import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def classification(input_dir, resultcsv):\n",
    "    \n",
    "    \"\"\"classification function uses ClassyFire ChemONT\n",
    "\n",
    "    Parameters:\n",
    "    input_dir (str): This is the input directory where all the .mzML \n",
    "    files and their respective result directories are stored.\n",
    "    \n",
    "    resultcsv: csv of df from combine_CuratedR or checkSMILES_validity\n",
    "    \n",
    "    Returns:\n",
    "    dataframe: with classification\n",
    "    csv: \"MetabolomicsResults/final_curationList.csv\"\n",
    "    \n",
    "    Usage:\n",
    "    checkSMILES_validity(input_dir = \"usr/project/\", frame)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def isNaN(string):\n",
    "        return string != string\n",
    "    frame = pd.read_csv(resultcsv)\n",
    "    inchis = []\n",
    "    for i, row in frame.iterrows():\n",
    "        if not isNaN(frame['SMILES_final'][i]) and isNaN(frame['Classification_Source'][i]):\n",
    "            try:\n",
    "                InChI = Chem.MolToInchi(Chem.MolFromSmiles(frame[\"SMILES_final\"][i]))\n",
    "                InChIKey = Chem.inchi.InchiToInchiKey(InChI)\n",
    "                inchis.append({\n",
    "                    'index': i,\n",
    "                    'smiles':frame[\"SMILES_final\"][i],\n",
    "                    'inchi': InChI,\n",
    "                    'inchikey': InChIKey\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "    inchis = pd.DataFrame(inchis)\n",
    "    inchis = inchis.loc[-isNaN(inchis['inchikey'])]\n",
    "    ## Retrieve ClassyFire classifications ##\n",
    "    \n",
    "    # This first step is done using inchikey and interrogation of the gnps classified structures\n",
    "    gnps_proxy = True \n",
    "    url = \"http://classyfire.wishartlab.com\"\n",
    "    proxy_url =  \"https://gnps-classyfire.ucsd.edu\"\n",
    "    chunk_size = 1000\n",
    "    sleep_interval = 12\n",
    "    \n",
    "    all_inchi_keys = list(inchis['inchikey'].drop_duplicates())\n",
    "\n",
    "    resolved_ik_number_list = [0, 0]\n",
    "    total_inchikey_number = len(all_inchi_keys)\n",
    "\n",
    "    while True:\n",
    "    \n",
    "        start_time = time.time()\n",
    "    \n",
    "        print('%s inchikey to resolve' % total_inchikey_number )\n",
    "        get_classifications_cf_mod(all_inchi_keys, par_level = 6)\n",
    "    \n",
    "        cleanse('all_json.json', 'all_json.json')\n",
    "    \n",
    "        with open(\"all_json.json\") as tweetfile:\n",
    "            jsondic = json.loads(tweetfile.read())\n",
    "\n",
    "        df = json_normalize(jsondic)\n",
    "        df = df.drop_duplicates( 'inchikey' )\n",
    "        resolved_ik_number = len( df.drop_duplicates('inchikey').inchikey )\n",
    "        resolved_ik_number_list.append( resolved_ik_number )\n",
    "        print('%s resolved inchikeys' % resolved_ik_number )\n",
    "        print(\"done in --- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "        if resolved_ik_number_list[-1] < resolved_ik_number_list[-2] or resolved_ik_number_list[-1] == resolved_ik_number_list[-3]:\n",
    "            break\n",
    "        cleanse('all_json.json', 'all_json_cleaned.json')\n",
    "        \n",
    "        with open(\"all_json_cleaned.json\") as tweetfile:\n",
    "            jsondic = json.loads(tweetfile.read())\n",
    "            \n",
    "    flattened_classified_json = json_normalize(jsondic)\n",
    "    flattened_df = flattened_classified_json.drop_duplicates('inchikey')\n",
    "    flattened_df['inchikey'] = flattened_df['inchikey'].str.replace(r'InChIKey=', '')\n",
    "    df_merged = pd.merge(inchis, flattened_df, left_on='inchikey', right_on='inchikey', how='left')\n",
    "    \n",
    "    for p, rowp in df_merged.iterrows():\n",
    "        for q, rowq in frame.iterrows():\n",
    "            if df_merged[\"smiles_x\"][p] is frame[\"SMILES_final\"][q]:\n",
    "                frame.loc[q, 'subclass'] = df_merged[\"subclass.name\"][p]\n",
    "                frame.loc[q, 'class'] = df_merged[\"class.name\"][p]\n",
    "                frame.loc[q, 'superclass'] = df_merged[\"superclass.name\"][p]\n",
    "                frame.loc[q, 'Classification_Source'] = \"ClassyFire\"\n",
    "    #frame.to_csv(input_dir, '/SIRIUS_combined.csv')\n",
    "    return(frame)\n",
    "\n",
    "    frame.to_csv(input_dir + \"MetabolomicsResults/final_curationList.csv\")\n",
    "    \n",
    "classification(sys.argv[1], sys.argv[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mawRpy)",
   "language": "python",
   "name": "mawrpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
